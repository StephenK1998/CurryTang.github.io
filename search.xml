<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title></title>
      <url>%2Fposts%2Funcategorized%2F2017-01-29-UCB%20CS61A%20Python%20%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8%20(Composing%20Programs%204.8%20%E8%8A%82)%20%E7%BF%BB%E8%AF%91.html</url>
      <content type="text"><![CDATA[UCB CS61A Python 并发编程入门 (Composing Programs 4.8 节) 翻译 原作地址(访问可能较慢): The original version 原作者: John Denero 关于Composing Programs:Composing Programs is authored and maintained by John DeNero. Please direct corrections and contributions directly to him via email. The text was originally published as lecture notes for CS 61A at UC Berkeley and is based upon the Structure and Interpretation of Computer Programs by Harold Abelson and Gerald Jay Sussman. 背景介绍从1970年代到2000年代中期， 单个处理器核心的处理速率以幂级增长。这些增长中的大部分要归功于时钟频率的提高， 即处理器进行基本运算的速率。 然而，到了2000年代中期，由于功率与 发热的限制，这种增长戛然而止。从那时起，单个处理器核心处理速率的增幅也大幅下降。CPU生产商们便在一个处理器中放置了更多的处理核心，使更多的运算能够并发地完成。 并发并不是一个新概念。 大规模的并行计算机已经被运用了数十年， 尤其是在科学计算与数据分析的领域之中。 甚至在只有单个核心的个人计算机中， 操作系统与解释器也提供了异步的抽象。这是由上下文切换来实现的， 或者在不等待任务完成的情况下在他们之间迅速地切换。因此，即使只有一颗核心， 大多数程序也还是可以在一台机器上异步地被执行。 考虑到目前增加处理器核心数的大趋势， 个人应用就更要抓住并发的优势以获得更快的运行速度。在一个程序内， 我们应当采取处理速度最快的那一种计算（顺序）。然而，并发给程序的正确性带来了新的挑战， 尤其是那些共享的，可变的数据。 对于那些没有共享的，可变的数据， 并且可以在函数式编程的模型下有效解决的问题， 并发模型不会给程序员们带来麻烦。 纯函数带来了一种 指示的透明性， 意味着表达式可以由它的值来代替。这使得并行运算时， 不同的表达式不需要互相依赖来执行计算。我们在先前的章节提到过， MapReduce 框架使得程序员们能够很轻松地让自己的程序并发的执行。 不幸的是， 并不是所有的问题都能在函数式的模型下有效地被解决。在伯克利大学视图项目中提出的科学与工程领域的十三个常见计算模型中，只有MapReduce能以函数式模型有效解决，其余的都需要共享的数据状态。 在本节余下的部分中， 我们将看到可变的共享数据所带来的麻烦， 以及一些解决的方案。我们将以爬虫与粒子模拟器为例。 4.8.1 Python 中的并发在我们深入并发地细节之前， 让我们先来探索一下Python对并行计算的支持。Python中有两种主要的并行计算方法：线程与多进程。 线程在线程模型中， 许多个线程在一个单独的解释器中同时运行。虽然共享数据，但每一个线程在不依赖其他线程的情况下独立运行。然而，Python的主要实现CPython一次只运行一个线程里的代码，在它们之间切换来达到并行的假象。另一方面，外部运行的操作，例如写文件与联网，可能可以并发地执行。 threading模块提供了必要的类来创建线程并且同步地被执行。以下是一个简单的例子： 12345678910&gt;&gt;&gt; import threading&gt;&gt;&gt; def thread_hello(): other = threading.Thread(target=thread_say_hello, args=()) other.start() thread_say_hello()&gt;&gt;&gt; def thread_say_hello(): print('hello from', threading.current_thread().name)&gt;&gt;&gt; thread_hello()hello from Thread-1hello from MainThread Thread构造函数创建一个新线程。它需要一个新的线程应该运行的目标函数，以及该函数的参数。在Thread对象上调用start标记它准备好运行。 current_thread函数返回与当前执行线程相关联的Thread对象。 在这个例子中，print可以以任何顺序发生，因为我们没有以任何方式同步它们。 多进程Python也支持多进程，这是一种使程序能够大量产生多个解释程序，或者说进程的机制， 每一个进程可以独立地运行。这些进程通常并不共享数据，所以任何共享的状态一定要在进程间传递。另一方面，进程根据由相应的操作系统与硬件提供的并发等级来并行执行。因此，如果一个CPU有多个核心，那么Python进程就可以做到真正的并发。 Python的multiprocessing模块提供了用来创建并同步执行进程的类。这是用进程重写的hello程序。12345678910&gt;&gt;&gt; import multiprocessing&gt;&gt;&gt; def process_hello(): other = multiprocessing.Process(target=process_say_hello, args=()) other.start() process_say_hello()&gt;&gt;&gt; def process_say_hello(): print('hello from', multiprocessing.current_process().name)&gt;&gt;&gt; process_hello()hello from MainProcess&gt;&gt;&gt; hello from Process-1 就像例子中的那样，multiprocessing中的函数与类同threading模块是类似的。这个例子同时展示了信息同步的缺乏是如何影响共享的状态的，因为输出也可以被认为是一种共享的状态。在这里，解释器终端的交互部分在其它进程结束前便被打印了出来。 4.8.2 共享状态带来的问题为了进一步展示共享状态带来的问题， 让我们来看一个使用了在两个线程间共享状态的计数器的例子。 1234567891011121314import threadingfrom time import sleepcounter = [0]def increment(): count = counter[0] sleep(0) # try to force a switch to the other thread counter[0] = count + 1other = threading.Thread(target=increment, args=())other.start()increment()print('count is now: ', counter[0]) 在这个程序中，两个线程尝试增加相同的计数器。 CPython解释器几乎可以在任何时间在线程之间切换。只有最基本的操作是原子操作，这意味着它们会即刻发生，在执行期间不可能进行切换。递增计数器需要多个基本操作：读取旧值，向其中添加一个值，然后写入新值。解释器可以在任何这些操作之间切换线程。为了显示当解释器在错误的时间切换线程时发生了什么，我们尝试通过睡眠0秒强制切换。当运行此代码时，解释器通常在睡眠调用时切换线程。这可以导致以下操作序列：1234567Thread 0 Thread 1read counter[0]: 0 read counter[0]: 0calculate 0 + 1: 1write 1 -&gt; counter[0] calculate 0 + 1: 1 write 1 -&gt; counter[0] 最终结果是，即使计数器递增两次，计数器的值为1！更糟糕的是，解释器很少会发生这样的错误，这使得程序难以调试。即使使用sleep调用，此程序有时会产生2的正确计数，有时会产生不正确的计数1。 这个问题有一块共享数据可以被一个线程改变，而且另一个线程也可以访问时出现。这种冲突被称为竞争条件，并且它是仅存在于并行世界中的错误的示例。 为了避免竞争条件，可能被多个线程改变和访问的共享数据必须被保护以防止并发访问。例如，如果我们可以确保线程1仅在线程0完成访问计数器之后访问计数器，反之亦然，我们可以保证计算正确的结果。我们说，如果共享数据受到保护而不能同时访问，则它将同步。在接下来的几个小节中，我们将看到多个提供同步的机制。 4.8.3 当没有必要进行同步时在某些情况下，如果并发访问不会导致不正确的行为，则无需同步对共享数据的访问。 最简单的示例是只读数据。 由于这种数据从未被改变，所以所有线程将总是读取相同的值，而不管它们何时访问数据。在极少数情况下，变更的共享数据可能不需要同步。 然而，了解这种情况需要深入了解解释器和底层软件和硬件的工作原理。 请考虑以下示例： 12345678910111213141516items = []flag = []def consume(): while not flag: pass print('items is', items)def produce(): consumer = threading.Thread(target=consume, args=()) consumer.start() for i in range(10): items.append(i) flag.append('go')produce() #一种可能的输出：items is [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] 这里，生产者线程将项目添加到项目，而消费者等待直到标志不为空。 当生产者完成添加项目时，它向标志添加一个元素，允许消费者继续。 在大多数Python实现中，此示例将正常工作。 然而，其他编译器和解释器，甚至硬件本身的一个常见的优化是在单个线程中重新排序操作，这些操作不依赖于数据。 在这样的系统中，语句flag.append（’go’）可以在循环之前移动，因为它们对于数据都不取决于另一个。 一般来说，你应该避免这样的代码，除非你确定底层系统不会重新排序相关的操作。 4.8.4 同步的数据结构同步共享数据的最简单的方法是使用提供同步操作的数据结构。 队列模块包含一个Queue类，它提供同步的先进先出访问数据。 put方法将一个项目添加到队列，并且get方法检索项目。 类本身确保这些方法是同步的，所以项目不会丢失，无论打乱交织线程操作。 这里是使用队列的生产者/消费者示例: 123456789101112131415161718from queue import Queuequeue = Queue()def synchronized_consume(): while True: print('got an item:', queue.get()) queue.task_done()def synchronized_produce(): consumer = threading.Thread(target=synchronized_consume, args=()) consumer.daemon = True consumer.start() for i in range(10): queue.put(i) queue.join()synchronized_produce() 除了Queue和get和put调用之外，这个代码还有一些改变。我们已将消费者线程标记为守护程序，这意味着程序不会在退出之前等待该线程完成。这允许我们在消费者中使用无限循环。但是，我们需要确保主线程退出，但只有在所有项目从队列中消耗之后。消费者调用task_done方法来通知队列它已完成处理一个项目，而主线程调用join方法，该方法等待所有项目被处理，确保程序只在这种情况之后退出。 使用队列的更复杂的示例是搜索网站上的死链接的并行网络爬虫。此抓取工具遵循由同一网站托管的所有链接，因此必须处理多个网址，不断向“队列”中添加新网址并删除要处理的网址。通过使用同步队列，多个线程可以安全地同时向数据结构添加和删除。 #爬虫程序的链接： Crawler 4.8.5 锁当特定数据结构的同步版本不可用时，我们必须提供自己的同步。锁是这样做的基本机制。它可以由至多一个线程获取，之后没有其他线程可以获取它，直到它被先前获取它的线程释放。 在Python中，线程模块包含一个Lock类来提供锁定。锁具有获取和释放方法来获取和释放锁，类保证每次只有一个线程可以获取它。所有其他尝试获取已经被锁定的锁的线程被迫等待，直到它被释放。 对于一个锁来保护一组特定的数据，所有的线程需要遵循一个规则：没有线程能够访问任何共享数据，除非它拥有那个特定的锁。实际上，所有线程需要在获取和释放对该锁的调用中“包装”它们对共享数据的操作。 在并行网络爬虫中，使用一个集合数据结构来跟踪任何线程已经遇到的所有URL，以避免不止一次处理特定URL（并且可能在一个死循环中停滞）。但是，Python不提供同步集，因此我们必须使用锁来保护对正常集的访问： 1234567891011seen = set()seen_lock = threading.Lock()def already_seen(item): seen_lock.acquire() result = True if item not in seen: seen.add(item) result = False seen_lock.release() return result 这里需要一个锁，以防止另一个线程在该线程检查一个URL是否在集合中时将一个URL添加进集。 此外，添加到集合的操作不是原子级的，因此并发尝试添加到集合可能会损坏其内部数据。在这段代码中，我们必须小心不要return，直到我们释放锁。 一般来说，我们必须确保当我们不再需要锁时释放锁。 这可能非常容易出错，特别是在异常存在的情况下，所以Python为我们提供了一个with语句来处理获取和释放锁: 123456def already_seen(item): with seen_lock: if item not in seen: seen.add(item) return False return True with语句确保seen_lock在上下文执行之前被获取，并且当上下文因任何原因退出时被释放。 （with语句实际上可以用于锁定以外的操作，但我们不会在这里介绍其他用法。）必须彼此同步的操作必须使用相同的锁。 然而，必须仅与同一集合中的操作同步的两个不相交的操作集合应当使用两个不同的锁对象以避免过度同步。 4.8.6 屏障避免对共享数据的冲突访问的另一种方式是将程序分成阶段，以确保共享数据在没有其他线程访问共享数据的阶段中被改变。 屏障通过要求所有线程在任何线程可以继续之前到达它来将程序分成多个阶段。 在屏障之后执行的代码不能与在屏障之前执行的代码并发。 在Python中，线程模块以Barrier实例的wait方法的形式提供了一个障碍： 1234567891011121314151617counters = [0, 0]barrier = threading.Barrier(2)def count(thread_num, steps): for i in range(steps): other = counters[1 - thread_num] barrier.wait() # wait for reads to complete counters[thread_num] = other + 1 barrier.wait() # wait for writes to completedef threaded_count(steps): other = threading.Thread(target=count, args=(1, steps)) other.start() count(0, steps) print('counters:', counters)threaded_count(10) 在此示例中，对共享数据的读取和写入发生在由屏障分隔的不同阶段。写入发生在同一阶段，但它们是不相交的;这种不相交是必要的，以避免同一阶段中的相同数据的并发写入。由于此代码已正确同步，因此两个计数器在结束时始终为10。 多线程粒子仿真器以类似方式使用障碍来同步对共享数据的访问。在模拟中，每个线程拥有多个粒子，所有这些粒子在许多离散时间步长的过程中彼此交互。粒子具有位置，速度和加速度，并且基于其他粒子的位置在每个时间步长中计算新的加速度。粒子的速度必须相应地更新，并且根据其速度来改变其位置。 与上面的简单示例一样，存在一个读取阶段，其中所有粒子的位置被所有线程读取。每个线程在这个阶段更新自己的粒子加速度，但由于这些是不相交的写入，它们不需要同步。在写阶段，每个线程更新自己的粒子的速度和位置。同样，这些是不相交的写入，并且它们被屏障保护免于读取阶段。 4.8.7 消息传递避免共享数据的不当改变的最终机制是完全避免对相同数据的并发访问。 在Python中，使用多进程而不是线程自然会导致这一点，因为进程在具有自己的数据的单独的解释器中运行。 可以通过在进程之间传递消息来传达多个进程所需的任何状态。多进程模块中的管道类提供了进程之间的通信通道。 默认情况下，它是双工的，意味着双向通道，虽然传递参数False导致单向通道。 send方法通过通道发送一个对象，而recv方法接收一个对象。 后者是阻塞，意味着调用recv的进程将等待直到接收到对象。以下是使用进程和管道的生产者/消费者示例： 12345678910111213141516def process_consume(in_pipe): while True: item = in_pipe.recv() if item is None: return print('got an item:', item)def process_produce(): pipe = multiprocessing.Pipe(False) consumer = multiprocessing.Process(target=process_consume, args=(pipe[0],)) consumer.start() for i in range(10): pipe[1].send(i) pipe[1].send(None) # done signalprocess_produce() 在这个例子中，我们使用None来表示通信的结束。我们还在创建consumer进程时将管道的一端作为目标函数的参数传递。这是必要的，因为状态必须在进程之间显式共享。 粒子模拟器的多线程版本使用管道在每个步骤中的进程之间传递粒子位置。事实上，它使用管道在进程之间建立一个完整的循环管道，以便最小化通信。每个过程将其自己的粒子位置注入其管线阶段，其最终经历管线的完全旋转。在旋转的每个步骤，过程将力从当前在其自己的管道阶段中的位置施加到其自己的颗粒上，使得在完全旋转之后，所有的力已经被施加到其颗粒。 多进程模块为进程提供了其他同步机制，包括同步队列，锁和Python 3.3的障碍。例如，锁或屏障可以用于将打印同步到屏幕，避免了我们之前看到的不正确的显示输出。 4.8.8 同步的陷阱虽然同步方法对于保护共享状态有效，但是它们也可能被不正确地使用，无法完成正确的同步，过度同步或导致程序因死锁而挂起。 欠同步。并行计算中的常见缺陷是忽略正确同步共享访问。在集合示例中，我们需要将成员资格检查和插入同步到一起，以便另一个线程不能在这两个操作之间执行插入。无法将两个操作同步在一起是错误的，即使它们是单独同步的。 过度同步。另一个常见的错误是过度同步程序，使得非冲突操作不能同时发生。作为一个简单的例子，我们可以通过在线程启动时获取主锁来避免对共享数据的所有冲突访问，并且只在线程完成时释放它。这将序列化我们的整个代码，所以没有并行运行。在某些情况下，这甚至可能导致我们的程序无限期地挂起。例如，考虑消费者/生产者程序，其中消费者获得锁并且从不释放它。这防止生产者产生任何物品，这反过来防止消费者做任何事情，因为它没有什么可消耗。 虽然这个例子是微不足道的，但在实践中，程序员经常在一定程度上过度同步它们的代码，防止他们的代码完全利用可用的并行性。 死锁。因为它们使线程或进程彼此等待，所以同步机制容易受到死锁的影响，其中两个或多个线程或进程被卡住，等待彼此完成。我们刚刚看到了如何忽略释放锁可以导致线程无限期地被卡住。但即使线程或进程正确释放锁，程序仍可能达到死锁。 死锁的来源是循环等待，下面用过程来说明。没有进程可以继续，因为它正在等待其它正在等待完成的进程。 例如，我们将设置一个具有两个进程的死锁。 假设它们共享双工管道并尝试如下彼此通信： 123456789101112def deadlock(in_pipe, out_pipe): item = in_pipe.recv() print('got an item:', item) out_pipe.send(item + 1)def create_deadlock(): pipe = multiprocessing.Pipe() other = multiprocessing.Process(target=deadlock, args=(pipe[0], pipe[1])) other.start() deadlock(pipe[1], pipe[0])create_deadlock() 这两个进程都尝试首先接收数据。 回想一下，recv方法阻塞，直到一个项目可用。 由于两个进程都没有发送任何东西，两者都将无限期地等待另一个发送它的数据，导致死锁。同步操作必须正确对齐，以避免死锁。 这可能需要在接收之前通过管道发送，以相同的顺序获取多个锁，并且确保所有线程在正确的时间到达正确的屏障。 4.8.9 结语正如我们所看到的，并行性在编写正确和高效的代码时提出了新的挑战。 随着在可预见的未来硬件级别上增加并行性的趋势将继续，并行计算在应用程序编程中将变得越来越重要。 有很多的研究正致力于使程序员们更简单地写出并行的、更少错误的程序。 我们在这里的讨论只是作为计算机科学这一关键领域的基本介绍。 翻译者:c.z.k]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Fluent Python Note Tip1:字典（上）]]></title>
      <url>%2Fposts%2Funcategorized%2F2017-01-25-Python%20Tips%20every%20day(Fluent%20Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0).html</url>
      <content type="text"><![CDATA[#Python Tips every day(Fluent Python学习笔记) ##Tip1:字典（上） 字典可以说是Python中最常用的数据结构之一，但它也有一些不那么为人所知的奇技淫巧，掌握它们，有助于Python程序员写出更优雅、更Pythonic的代码。 ###1.Python中映射类的继承关系 Python中的映射类从Container, Iterable, Sized三个接口继承而来，最基本的映射类为Mapping类(Abstract Class)，它实现了__getitem__ , get, keys, items等方法， 再接下来派生出了MutableMapping类，我们常用的dict便隶属于此。 In [29]: Mapping.__dict__.keys() Out[29]: dict_keys(['_abc_registry', 'get', '__doc__', '__getitem__', '_abc_negative_cache_version', '__contains__', '__module__', '__abstractmethods__', '__slots__', '_abc_cache', '_abc_negative_cache', 'items', 'values', '__eq__', '__hash__', 'keys']) In [30]: [method for method in MutableMapping.__dict__.keys() if method not in Mapping.__dict__.keys()] Out[30]: ['update', 'pop', '_MutableMapping__marker', '__setitem__', '__delitem__', 'setdefault', 'popitem', 'clear'] ###2.字典的键 什么样的值都能当作字典的键吗？Absolutely Not. Python规定Hashable Objects必须实现__hash__与__eq__这两个通用接口。简单的来说，必须是运行时不可变的值。废话少说，来看几个例子。 In [31]: my_dict = {} In [32]: key1 = [1] #不可以，list unhashable In [33]: key2 = (1,) #可以 In [34]: key3 = (1,[1,2]) #不可以，元组只要在元素都hashable时才可以做键 In [35]: key4 = (1,(1,2)) #可以 In [36]: key5 = 'abcs' #可以 In [37]: key6 = set(3,4) #不可以，set unhashable, frozenset可以用作键 一句话来总结一下，“All of Python’s immutable built-in objects are hashable” (Cited from Python Glossary) ###3. 构造字典（创建一个字典的n种方法） ####1. 重载的构造函数dict() In [43]: dict1 = dict(a = 1, b = 2) In [44]: dict2 = {'a':1, 'b':2} In [45]: dict3 = dict(zip(['a','b'],[1,2])) [1] In [46]: dict4 = dict([('a',1),('b',2)]) In [47]: dict5 = dict({'a':1, 'b':2}) In [48]: dict1 == dict2 == dict3 == dict4 == dict5 Out[48]: True Notes:[1]Find more information about zip(): zip ####2. 使用dict comprehension类似于List Comprehesion, 字典推导式提供了一种优雅、简洁的方式来创建一个Python字典。 字典推导式的语法在Python2.7 以及 3 以后是这样的 d = {k:v for k, v in iterable} 需要注意的是之前 d = {(k,v) for k, v in iterable}的写法已不再适用。 下面给出一些简单的样例In [1]: three_point_shooting = [ …: (‘curry’,99), …: (‘thompson’,98), …: (‘durant’,90), …: (‘james’,70)]In [2]: three_point_map = {player_name:ability for player_name, ability in three_point_shooting}In [3]: three_point_mapOut[3]: {‘curry’: 99, ‘durant’: 90, ‘james’: 70, ‘thompson’: 98}In [4]: {player.upper():ability for player, ability in three_point_map.items()}Out[4]: {‘CURRY’: 99, ‘DURANT’: 90, ‘JAMES’: 70, ‘THOMPSON’: 98}]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Test post]]></title>
      <url>%2Fposts%2Funcategorized%2F2017-01-03-Test-post.html</url>
      <content type="text"></content>
    </entry>

    
    <entry>
      <title><![CDATA[Hello World]]></title>
      <url>%2Fposts%2Funcategorized%2F2016-12-30-hello-world.html</url>
      <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
    </entry>

    
  
  
</search>
